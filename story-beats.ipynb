{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84bd53d",
   "metadata": {},
   "source": [
    "# Story Beats\n",
    "\n",
    "## Overview \n",
    "The goal of the competition is to predict the story beat of a scene in a given movie. According to Blake Snyder's Save the Cat! categorization, there are 15 possible story beats:\n",
    "\n",
    "    1. Opening Image\n",
    "    2. Theme Stated\n",
    "    3. Setup\n",
    "    4. Catalyst\n",
    "    5. Debate\n",
    "    6. Break Into Two\n",
    "    7. B Story\n",
    "    8. Fun and Games\n",
    "    9. Midpoint\n",
    "    10. Bad Guys Close In\n",
    "    11. All is Lost\n",
    "    12. Dark Night of the Soul\n",
    "    13. Break Into Three\n",
    "    14. Finale\n",
    "    15. Final Image\n",
    "\n",
    "The student's task is to create an algorithm that predicts one of these story beats based on scene stats and a subtitle file.\n",
    "\n",
    "## Description \n",
    "The submissions will be evaluated using classification accuracy. To create a predictive model, students should use Python and scikit-learn (or any other applicable machine learning toolkit).\n",
    "\n",
    "In addition to submitting their solution on this site, students are required to provide a link to reproducible code in the form of a Jupyter Notebook on the Course website. This project can be done in pairs.\n",
    "\n",
    "## Authors\n",
    "The notebook was prepared as part of the subject Advanced Data Mining, project number 2, project for a group of two people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65393cfa-0194-480f-8636-7fd479169bf6",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f8cd08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "import chardet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345ceb9",
   "metadata": {},
   "source": [
    "Load test files - paths & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2771f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = './data/test'\n",
    "test_features_path = os.path.join(test_folder, \"features\")\n",
    "\n",
    "test_features_files = glob.glob(os.path.join(test_features_path, '*.csv'))\n",
    "test_timestamps_files = glob.glob(os.path.join(test_folder, 'scene_timestamps', '*.csv'))\n",
    "test_subtitles_files = glob.glob(os.path.join(test_folder, 'subtitles', '*.srt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92dfee",
   "metadata": {},
   "source": [
    "Load training files - paths & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3328c36-ef5a-4b8f-a44b-d5c66d13c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomstate = 40 #aby zapewnić powtarzalność\n",
    "train_folder = './data/train'\n",
    "train_features_path =  os.path.join(train_folder, \"features\")\n",
    "\n",
    "train_features_files = glob.glob(os.path.join(train_features_path, '*.csv'))\n",
    "train_labels_files = glob.glob(os.path.join(train_folder, 'labels', '*.csv'))\n",
    "train_timestamps_files = glob.glob(os.path.join(train_folder, 'scene_timestamps', '*.csv'))\n",
    "train_subtitles_files = glob.glob(os.path.join(train_folder, 'subtitles', '*.srt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be0c09-36ac-4741-a89a-666c7fa8bf97",
   "metadata": {},
   "source": [
    "### Utility Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54917015-09ae-40e3-b560-76e5bd8600a7",
   "metadata": {},
   "source": [
    "#### 1. Read subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7097c67c-7c21-43bd-9ab2-756405c04353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#na problemy z wczytywaniem pliku i złymi znakami\n",
    "def read_srt_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads an SRT file, detecting its encoding and handling any issues with invalid characters.\n",
    "\n",
    "    This function first detects the file's encoding using the chardet library, and then reads the file using the detected encoding.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the SRT file to be read.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the SRT file as a string.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        detector = chardet.UniversalDetector()\n",
    "        for line in file:\n",
    "            detector.feed(line)\n",
    "            if detector.done:\n",
    "                break\n",
    "        detector.close()\n",
    "\n",
    "    encoding = detector.result['encoding']\n",
    "    \n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        content = file.read()\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a2db2-990f-43e5-87ae-78f0ad56cb08",
   "metadata": {},
   "source": [
    "#### 2. Removing HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deda0d60-18e7-4fea-842a-a86c6610a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#na problemy z źle sformatownaym tekstem (nie powinien mieć tagów)\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"\n",
    "    Removes HTML tags from the given text.\n",
    "\n",
    "    This function uses BeautifulSoup to parse the input text and extract plain text, removing any HTML tags.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text containing HTML tags.\n",
    "\n",
    "    Returns:\n",
    "    str: The plain text with HTML tags removed.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    plain_text = soup.get_text(separator=' ', strip=True)\n",
    "    return plain_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3283995d-62ca-476a-8252-c38797b671ee",
   "metadata": {},
   "source": [
    "#### 3. Parsing subtitles\n",
    "\n",
    "In this function, we perform the following tasks:\n",
    "- Normalize sentences\n",
    "- Decipher abbreviations\n",
    "- Expand abbreviations\n",
    "- Remove the corpus\n",
    "- Lemmatize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56e0eac9-f712-4a72-959d-4e6cbb5adcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse_subtitles(subtitles_files_list):\n",
    "    subtitles_df = pd.DataFrame()\n",
    "    for file_path in subtitles_files_list:\n",
    "\n",
    "        name = file_path.split('\\\\')[-1].split('_')[0] # movieId\n",
    "        srt_content = read_srt_file(file_path)\n",
    "\n",
    "        subtitles = re.split(r'\\n\\n', srt_content.strip())[:]\n",
    "        data = {'id': [], 'start': [], 'end': [], 'text': []}\n",
    "\n",
    "        for subtitle in subtitles:\n",
    "            start = \"\"\n",
    "            end = \"\"\n",
    "            lines = subtitle.strip().split('\\n')\n",
    "            \n",
    "            try:\n",
    "                data['id'].append(int(lines[0]))\n",
    "            except ValueError as e:\n",
    "                print(f\"Error parsing int: {file_path}. subtitle: {subtitle}, int: {lines}\")\n",
    "                continue\n",
    "    \n",
    "            try:\n",
    "                time_pattern = r'(\\d+:\\d+:\\d+[,.]\\d+) --> (\\d+:\\d+:\\d+[,.]\\d+)'\n",
    "                start, end = re.findall(time_pattern, lines[1])[0]\n",
    "\n",
    "                start_times = start.split(\":\")\n",
    "                start_seconds = str(start_times[-1]).replace(\",\", \".\").split(\".\")\n",
    "                start = int(start_times[0])*60*60+int(start_times[1])*60+int(start_seconds[0]) + int(start_seconds[1])/1000\n",
    "\n",
    "                end_times = end.split(\":\")\n",
    "                end_seconds = str(end_times[-1]).replace(\",\", \".\").split(\".\")\n",
    "                end = int(end_times[0])*60*60 + int(end_times[1]) * 60 + int(end_seconds[0]) + int(end_seconds[1])/1000\n",
    "            except ValueError as e:\n",
    "                print(f\"file_name: {file_path}. start: {start}, end: {end}\")\n",
    "                continue\n",
    "    \n",
    "            data['start'].append(start)\n",
    "            data['end'].append(end)\n",
    "            \n",
    "            text = ' '.join(lines[2:])\n",
    "            \n",
    "            #usuń niepotrzebne znaki\n",
    "            characters_to_remove = ':.,<>[];:\\'\"{}-i/()?!@#&*'\n",
    "            sno = SnowballStemmer('english')\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "            text = remove_html_tags(text)\n",
    "            text = contractions.fix(text) #napraw słowa, i'll -> i will\n",
    "            text = text.lower()\n",
    "\n",
    "            for char in characters_to_remove:\n",
    "                text = text.replace(char, '')\n",
    "            \n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            stop_words.add(\"\\an8\")\n",
    "\n",
    "            words = text.split()\n",
    "            filtered_words = [word for word in words if word not in stop_words] #usuwam slowa z listy stopwords\n",
    "            lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "            stemmed_words = [sno.stem(word) for word in lemmatized_words]\n",
    "            text = ' '.join(stemmed_words)\n",
    "            \n",
    "            data['text'].append(text)\n",
    "            data['movie_id'] = name\n",
    "\n",
    "        df_text = pd.DataFrame(data)\n",
    "        subtitles_df = pd.concat([subtitles_df, df_text], ignore_index=True)\n",
    "        \n",
    "    return subtitles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29eda7f-4bbf-44b7-88ad-3407a42d88ca",
   "metadata": {},
   "source": [
    "#### 4. Combine dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dcf5d9c-7a30-484d-8c9c-a84fcee51589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_join_text_df(combined_df, subtitles_df, check):\n",
    "    result_df_func = pd.merge(combined_df, subtitles_df, left_on=['id'], right_on=['movie_id'], how='left')\n",
    "    condition_func = (\n",
    "        (result_df_func['start_x'] <= result_df_func['start_y']) & \n",
    "        (result_df_func['start_y'] <= result_df_func['end_x'])\n",
    "    )\n",
    "    combined_df = result_df_func.copy()\n",
    "    combined_df.loc[~condition_func, ['text', 'start_y', 'end_y', 'id_y']] = '', '', '',''\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "    combined_df = combined_df.drop([\"id_y\"], axis=1)\n",
    "    combined_df = combined_df.rename(columns={'id_x': 'id', 'start_x': 'start', 'end_x': 'end', 'start_y': 'start_sub', 'end_y': 'end_sub'})\n",
    "\n",
    "\n",
    "    if check == 0:\n",
    "        combined_df = combined_df.groupby(['index', 'movie_id']).agg({\n",
    "        's_dur': 'first',\n",
    "        'n_shots': 'first',\n",
    "        'ava_shot_dur': 'first',\n",
    "        'rel_id_loc': 'first',\n",
    "        'rel_t_loc': 'first',\n",
    "        'ava_char_score': 'first',\n",
    "        'is_prot_appear': 'first',\n",
    "        'id': 'first',\n",
    "        # 'film_name': 'first',\n",
    "        'label_movie': 'first', # Label\n",
    "        'start': 'first',\n",
    "        'end': 'first',\n",
    "        'scene_order': 'first',\n",
    "        'start_sub': 'first',\n",
    "        'end_sub': 'first',\n",
    "        'text': ' '.join\n",
    "        }).reset_index()\n",
    "    else:\n",
    "        combined_df = combined_df.groupby(['index', 'movie_id']).agg({\n",
    "        's_dur': 'first',\n",
    "        'n_shots': 'first',\n",
    "        'ava_shot_dur': 'first',\n",
    "        'rel_id_loc': 'first',\n",
    "        'rel_t_loc': 'first',\n",
    "        'ava_char_score': 'first',\n",
    "        'is_prot_appear': 'first',\n",
    "        'id': 'first',\n",
    "        # 'film_name': 'first',\n",
    "        'start': 'first',\n",
    "        'end': 'first',\n",
    "        'scene_order': 'first',\n",
    "        'start_sub': 'first',\n",
    "        'end_sub': 'first',\n",
    "        'text': ' '.join\n",
    "        }).reset_index()\n",
    "\n",
    "    #posortowane jak w sample submission\n",
    "    #combined_df_func = combined_df.sort_values(by=['movie_id', 'index'])\n",
    "    #to sortowanie jest lepsze do porównywania labelek\n",
    "    combined_df_func = combined_df.sort_values(by=['index', 'movie_id'])\n",
    "    combined_df_func.loc[combined_df_func['text'] == '', 'text'] = 'None'\n",
    "    combined_df = combined_df_func.dropna()\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178a9b7",
   "metadata": {},
   "source": [
    "#### Load main data \n",
    "Load CSV files & normalize dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2906389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_combine(files_list):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in files_list:\n",
    "        id = file.split('\\\\')[-1].split('_')[0]\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        df = df.rename(columns={'Unnamed: 0': 'index'})\n",
    "        if 'labels' in file:\n",
    "            df = df.rename(columns={'0': 'label_movie'})\n",
    "\n",
    "        if 'timestamps' in file:\n",
    "            df['scene_order'] = range(1, len(df) + 1)\n",
    "\n",
    "        df['id'] = id\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def normalize_df(X_combined_df):\n",
    "    column_names = X_combined_df.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X_combined_df = scaler.fit_transform(X_combined_df)\n",
    "    X_combined_df = pd.DataFrame(data=X_combined_df, columns=column_names)\n",
    "    return X_combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17ad4e-0bdb-40ed-b9f5-c4222a8f9e7e",
   "metadata": {},
   "source": [
    "## Core Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c4c843-ebd7-4f83-bd0f-75e998cf8922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e6a3f-64b3-4d13-a6ab-cbc961de928f",
   "metadata": {},
   "source": [
    "#### 1. Load trainging & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9de4643f-0883-4a06-b86d-a67dbfb42008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing int: ./data/train\\subtitles\\tt0097576_indiana jones and the last crusade.srt. subtitle: Those people are\n",
      "trying to kill us!, int: ['Those people are', 'trying to kill us!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11712\\3203123836.py:14: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11712\\2399937301.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[~condition_func, ['text', 'start_y', 'end_y', 'id_y']] = '', '', '',''\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# First training data are loaded and combined into one dataframe \n",
    "###\n",
    "\n",
    "train_features_df = load_and_combine(train_features_files)\n",
    "train_labels_df = load_and_combine(train_labels_files)\n",
    "train_timestamps_df = load_and_combine(train_timestamps_files)\n",
    "train_subtitles_df = load_and_parse_subtitles(train_subtitles_files)\n",
    "\n",
    "temp_df = pd.merge(train_features_df, train_timestamps_df, on=['index', 'id'])\n",
    "train_movie_scene_df = pd.merge(temp_df, train_labels_df, on=['index', 'id'])\n",
    "train_movie_scene_df = filter_join_text_df(train_movie_scene_df, train_subtitles_df, 0)\n",
    "train_movie_scene_df = train_movie_scene_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dab7981a-4eab-42cd-ae87-d9e043528786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>s_dur</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>ava_shot_dur</th>\n",
       "      <th>rel_id_loc</th>\n",
       "      <th>rel_t_loc</th>\n",
       "      <th>ava_char_score</th>\n",
       "      <th>is_prot_appear</th>\n",
       "      <th>id</th>\n",
       "      <th>label_movie</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>scene_order</th>\n",
       "      <th>start_sub</th>\n",
       "      <th>end_sub</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0037884</td>\n",
       "      <td>218.718333</td>\n",
       "      <td>6</td>\n",
       "      <td>36.453056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1295.579078</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0037884</td>\n",
       "      <td>Opening Image</td>\n",
       "      <td>0.000</td>\n",
       "      <td>213.171</td>\n",
       "      <td>1</td>\n",
       "      <td>150.32</td>\n",
       "      <td>152.926</td>\n",
       "      <td>would better take th along gong cold farm ok m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0108160</td>\n",
       "      <td>75.992333</td>\n",
       "      <td>1</td>\n",
       "      <td>75.992333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1334.892862</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0108160</td>\n",
       "      <td>Opening Image</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0109830</td>\n",
       "      <td>108.525333</td>\n",
       "      <td>1</td>\n",
       "      <td>108.525333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>1622.833020</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0109830</td>\n",
       "      <td>Opening Image</td>\n",
       "      <td>176.718</td>\n",
       "      <td>176.718</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0119822</td>\n",
       "      <td>18.893333</td>\n",
       "      <td>2</td>\n",
       "      <td>9.446667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>895.328380</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0119822</td>\n",
       "      <td>Opening Image</td>\n",
       "      <td>25.359</td>\n",
       "      <td>36.245</td>\n",
       "      <td>1</td>\n",
       "      <td>28.779</td>\n",
       "      <td>32.617</td>\n",
       "      <td>gong get flower dear wll back n 20 mnute tulp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0037884</td>\n",
       "      <td>21.980333</td>\n",
       "      <td>3</td>\n",
       "      <td>7.326778</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.036189</td>\n",
       "      <td>1295.579078</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0037884</td>\n",
       "      <td>Opening Image</td>\n",
       "      <td>218.760</td>\n",
       "      <td>228.854</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sure n closet cannot fnd well look desk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   movie_id       s_dur  n_shots  ava_shot_dur  rel_id_loc  rel_t_loc  \\\n",
       "0      0  tt0037884  218.718333        6     36.453056    0.000000   0.000000   \n",
       "1      0  tt0108160   75.992333        1     75.992333    0.000000   0.000000   \n",
       "2      0  tt0109830  108.525333        1    108.525333    0.000000   0.020719   \n",
       "3      0  tt0119822   18.893333        2      9.446667    0.000000   0.003049   \n",
       "4      1  tt0037884   21.980333        3      7.326778    0.008403   0.036189   \n",
       "\n",
       "   ava_char_score  is_prot_appear         id    label_movie    start      end  \\\n",
       "0     1295.579078               1  tt0037884  Opening Image    0.000  213.171   \n",
       "1     1334.892862               1  tt0108160  Opening Image    0.000    0.000   \n",
       "2     1622.833020               1  tt0109830  Opening Image  176.718  176.718   \n",
       "3      895.328380               1  tt0119822  Opening Image   25.359   36.245   \n",
       "4     1295.579078               1  tt0037884  Opening Image  218.760  228.854   \n",
       "\n",
       "   scene_order start_sub  end_sub  \\\n",
       "0            1    150.32  152.926   \n",
       "1            1                      \n",
       "2            1                      \n",
       "3            1    28.779   32.617   \n",
       "4            2                      \n",
       "\n",
       "                                                text  \n",
       "0  would better take th along gong cold farm ok m...  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3  gong get flower dear wll back n 20 mnute tulp ...  \n",
       "4            sure n closet cannot fnd well look desk  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_movie_scene_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "215c753c-adde-43b2-9391-e85f2ad9c157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11712\\3203123836.py:14: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing int: ./data/test\\subtitles\\tt1285016_the social network.srt. subtitle: , int: ['']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11712\\2399937301.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[~condition_func, ['text', 'start_y', 'end_y', 'id_y']] = '', '', '',''\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11712\\2399937301.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[~condition_func, ['text', 'start_y', 'end_y', 'id_y']] = '', '', '',''\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Here tests data are loaded and combined into one dataframe \n",
    "###\n",
    "\n",
    "test_features_df = load_and_combine(test_features_files)\n",
    "test_timestamps_df = load_and_combine(test_timestamps_files)\n",
    "test_subtitles_df = load_and_parse_subtitles(test_subtitles_files)\n",
    "\n",
    "test_movie_scene_df = pd.merge(test_features_df, test_timestamps_df, on=['index', 'id'])\n",
    "test_movie_scene_df = filter_join_text_df(test_movie_scene_df, test_subtitles_df, 1)\n",
    "test_movie_scene_df = test_movie_scene_df.reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "test_movie_scene_df.to_csv('test_movie_scene_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea6a3144-181f-4481-ab4b-42a8cc9d690e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>s_dur</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>ava_shot_dur</th>\n",
       "      <th>rel_id_loc</th>\n",
       "      <th>rel_t_loc</th>\n",
       "      <th>ava_char_score</th>\n",
       "      <th>is_prot_appear</th>\n",
       "      <th>id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>scene_order</th>\n",
       "      <th>start_sub</th>\n",
       "      <th>end_sub</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt1142988</td>\n",
       "      <td>28.153333</td>\n",
       "      <td>3</td>\n",
       "      <td>9.384444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>2727.048221</td>\n",
       "      <td>1</td>\n",
       "      <td>tt1142988</td>\n",
       "      <td>67.317</td>\n",
       "      <td>90.507</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>alert okay well tell  wll n 15 mnute stop arg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tt1285016</td>\n",
       "      <td>225.934333</td>\n",
       "      <td>45</td>\n",
       "      <td>5.020763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>867.546640</td>\n",
       "      <td>1</td>\n",
       "      <td>tt1285016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>216.633</td>\n",
       "      <td>1</td>\n",
       "      <td>2.829</td>\n",
       "      <td>8.829</td>\n",
       "      <td>subttl ax sames cat dd know peopl wth genus q ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tt1568346</td>\n",
       "      <td>60.143333</td>\n",
       "      <td>6</td>\n",
       "      <td>10.023889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>175.028161</td>\n",
       "      <td>0</td>\n",
       "      <td>tt1568346</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45.879</td>\n",
       "      <td>1</td>\n",
       "      <td>30.68</td>\n",
       "      <td>33.16</td>\n",
       "      <td>knd know whte frame dark postmark last tme note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tt1632708</td>\n",
       "      <td>71.988333</td>\n",
       "      <td>29</td>\n",
       "      <td>2.482356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1440.813107</td>\n",
       "      <td>1</td>\n",
       "      <td>tt1632708</td>\n",
       "      <td>0.000</td>\n",
       "      <td>70.070</td>\n",
       "      <td>1</td>\n",
       "      <td>15.181</td>\n",
       "      <td>17.65</td>\n",
       "      <td>okay let u see could move th get rd kll knd fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0822832</td>\n",
       "      <td>32.240333</td>\n",
       "      <td>11</td>\n",
       "      <td>2.930939</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>2569.410356</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0822832</td>\n",
       "      <td>51.343</td>\n",
       "      <td>77.035</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\an8 cours exper kds even  crazi hound chasng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>309</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>42.375333</td>\n",
       "      <td>9</td>\n",
       "      <td>4.708370</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>993.294659</td>\n",
       "      <td>0</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>6033.945</td>\n",
       "      <td>6064.767</td>\n",
       "      <td>275</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>um mad honor um lve n wllamsburg wth roommat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>310</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>19.227333</td>\n",
       "      <td>1</td>\n",
       "      <td>19.227333</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.912490</td>\n",
       "      <td>1045.822997</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>6066.936</td>\n",
       "      <td>6066.936</td>\n",
       "      <td>276</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>311</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>13.180333</td>\n",
       "      <td>4</td>\n",
       "      <td>3.295083</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.915389</td>\n",
       "      <td>649.656064</td>\n",
       "      <td>0</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>6086.205</td>\n",
       "      <td>6095.965</td>\n",
       "      <td>277</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>312</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>7.173333</td>\n",
       "      <td>3</td>\n",
       "      <td>2.391111</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.917377</td>\n",
       "      <td>993.294659</td>\n",
       "      <td>0</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>6099.427</td>\n",
       "      <td>6103.806</td>\n",
       "      <td>278</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>314</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>80.664333</td>\n",
       "      <td>11</td>\n",
       "      <td>7.333121</td>\n",
       "      <td>0.996825</td>\n",
       "      <td>0.923199</td>\n",
       "      <td>889.912166</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0988595</td>\n",
       "      <td>6147.266</td>\n",
       "      <td>6205.533</td>\n",
       "      <td>279</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>th moment everythng hope  much dear belov gat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2470 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   movie_id       s_dur  n_shots  ava_shot_dur  rel_id_loc  \\\n",
       "0         0  tt1142988   28.153333        3      9.384444    0.000000   \n",
       "1         0  tt1285016  225.934333       45      5.020763    0.000000   \n",
       "2         0  tt1568346   60.143333        6     10.023889    0.000000   \n",
       "3         0  tt1632708   71.988333       29      2.482356    0.000000   \n",
       "4         1  tt0822832   32.240333       11      2.930939    0.008333   \n",
       "...     ...        ...         ...      ...           ...         ...   \n",
       "2465    309  tt0988595   42.375333        9      4.708370    0.980952   \n",
       "2466    310  tt0988595   19.227333        1     19.227333    0.984127   \n",
       "2467    311  tt0988595   13.180333        4      3.295083    0.987302   \n",
       "2468    312  tt0988595    7.173333        3      2.391111    0.990476   \n",
       "2469    314  tt0988595   80.664333       11      7.333121    0.996825   \n",
       "\n",
       "      rel_t_loc  ava_char_score  is_prot_appear         id     start  \\\n",
       "0      0.011692     2727.048221               1  tt1142988    67.317   \n",
       "1      0.000000      867.546640               1  tt1285016     0.000   \n",
       "2      0.000000      175.028161               0  tt1568346     0.000   \n",
       "3      0.000000     1440.813107               1  tt1632708     0.000   \n",
       "4      0.007405     2569.410356               1  tt0822832    51.343   \n",
       "...         ...             ...             ...        ...       ...   \n",
       "2465   0.906111      993.294659               0  tt0988595  6033.945   \n",
       "2466   0.912490     1045.822997               1  tt0988595  6066.936   \n",
       "2467   0.915389      649.656064               0  tt0988595  6086.205   \n",
       "2468   0.917377      993.294659               0  tt0988595  6099.427   \n",
       "2469   0.923199      889.912166               1  tt0988595  6147.266   \n",
       "\n",
       "           end  scene_order start_sub end_sub  \\\n",
       "0       90.507            1                     \n",
       "1      216.633            1     2.829   8.829   \n",
       "2       45.879            1     30.68   33.16   \n",
       "3       70.070            1    15.181   17.65   \n",
       "4       77.035            1                     \n",
       "...        ...          ...       ...     ...   \n",
       "2465  6064.767          275                     \n",
       "2466  6066.936          276                     \n",
       "2467  6095.965          277                     \n",
       "2468  6103.806          278                     \n",
       "2469  6205.533          279                     \n",
       "\n",
       "                                                   text  \n",
       "0      alert okay well tell  wll n 15 mnute stop arg...  \n",
       "1     subttl ax sames cat dd know peopl wth genus q ...  \n",
       "2     knd know whte frame dark postmark last tme note    \n",
       "3     okay let u see could move th get rd kll knd fr...  \n",
       "4      \\an8 cours exper kds even  crazi hound chasng...  \n",
       "...                                                 ...  \n",
       "2465   um mad honor um lve n wllamsburg wth roommat ...  \n",
       "2466                                               None  \n",
       "2467                                               None  \n",
       "2468                                               None  \n",
       "2469   th moment everythng hope  much dear belov gat...  \n",
       "\n",
       "[2470 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_movie_scene_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431df796-1ed1-4049-a98a-79d5f2cd3437",
   "metadata": {},
   "source": [
    "#### 2. Text processing\n",
    "Processing text into a version compatible with Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c049d37-fff3-4da1-b47b-42c96dc4e64f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>s_dur</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>ava_shot_dur</th>\n",
       "      <th>rel_id_loc</th>\n",
       "      <th>rel_t_loc</th>\n",
       "      <th>ava_char_score</th>\n",
       "      <th>is_prot_appear</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>wat</th>\n",
       "      <th>way</th>\n",
       "      <th>well</th>\n",
       "      <th>wll</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>wth</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0037884</td>\n",
       "      <td>218.718333</td>\n",
       "      <td>6</td>\n",
       "      <td>36.453056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1295.579078</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0037884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140783</td>\n",
       "      <td>0.368224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0108160</td>\n",
       "      <td>75.992333</td>\n",
       "      <td>1</td>\n",
       "      <td>75.992333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1334.892862</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0108160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0109830</td>\n",
       "      <td>108.525333</td>\n",
       "      <td>1</td>\n",
       "      <td>108.525333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>1622.833020</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0109830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0119822</td>\n",
       "      <td>18.893333</td>\n",
       "      <td>2</td>\n",
       "      <td>9.446667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>895.328380</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0119822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0037884</td>\n",
       "      <td>21.980333</td>\n",
       "      <td>3</td>\n",
       "      <td>7.326778</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.036189</td>\n",
       "      <td>1295.579078</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0037884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>305</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>57.390333</td>\n",
       "      <td>13</td>\n",
       "      <td>4.414641</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>0.952509</td>\n",
       "      <td>1154.750154</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.289726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>306</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>46.922333</td>\n",
       "      <td>10</td>\n",
       "      <td>4.692233</td>\n",
       "      <td>0.983923</td>\n",
       "      <td>0.958702</td>\n",
       "      <td>1154.750154</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>307</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>19.895333</td>\n",
       "      <td>6</td>\n",
       "      <td>3.315889</td>\n",
       "      <td>0.987138</td>\n",
       "      <td>0.963766</td>\n",
       "      <td>1154.750154</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>308</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>47.672333</td>\n",
       "      <td>15</td>\n",
       "      <td>3.178156</td>\n",
       "      <td>0.990354</td>\n",
       "      <td>0.965916</td>\n",
       "      <td>1154.750154</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>309</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>47.839333</td>\n",
       "      <td>1</td>\n",
       "      <td>47.839333</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.971060</td>\n",
       "      <td>1154.750154</td>\n",
       "      <td>1</td>\n",
       "      <td>tt0106918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3208 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   movie_id       s_dur  n_shots  ava_shot_dur  rel_id_loc  \\\n",
       "0         0  tt0037884  218.718333        6     36.453056    0.000000   \n",
       "1         0  tt0108160   75.992333        1     75.992333    0.000000   \n",
       "2         0  tt0109830  108.525333        1    108.525333    0.000000   \n",
       "3         0  tt0119822   18.893333        2      9.446667    0.000000   \n",
       "4         1  tt0037884   21.980333        3      7.326778    0.008403   \n",
       "...     ...        ...         ...      ...           ...         ...   \n",
       "3203    305  tt0106918   57.390333       13      4.414641    0.980707   \n",
       "3204    306  tt0106918   46.922333       10      4.692233    0.983923   \n",
       "3205    307  tt0106918   19.895333        6      3.315889    0.987138   \n",
       "3206    308  tt0106918   47.672333       15      3.178156    0.990354   \n",
       "3207    309  tt0106918   47.839333        1     47.839333    0.993569   \n",
       "\n",
       "      rel_t_loc  ava_char_score  is_prot_appear         id  ...  wat  way  \\\n",
       "0      0.000000     1295.579078               1  tt0037884  ...  0.0  0.0   \n",
       "1      0.000000     1334.892862               1  tt0108160  ...  0.0  0.0   \n",
       "2      0.020719     1622.833020               1  tt0109830  ...  0.0  0.0   \n",
       "3      0.003049      895.328380               1  tt0119822  ...  0.0  0.0   \n",
       "4      0.036189     1295.579078               1  tt0037884  ...  0.0  0.0   \n",
       "...         ...             ...             ...        ...  ...  ...  ...   \n",
       "3203   0.952509     1154.750154               1  tt0106918  ...  0.0  0.0   \n",
       "3204   0.958702     1154.750154               1  tt0106918  ...  0.0  0.0   \n",
       "3205   0.963766     1154.750154               1  tt0106918  ...  0.0  0.0   \n",
       "3206   0.965916     1154.750154               1  tt0106918  ...  0.0  0.0   \n",
       "3207   0.971060     1154.750154               1  tt0106918  ...  0.0  0.0   \n",
       "\n",
       "          well       wll work     would  wth      yeah  year  yes  \n",
       "0     0.140783  0.368224  0.0  0.294782  0.0  0.144425   0.0  0.0  \n",
       "1     0.000000  0.000000  0.0  0.000000  0.0  0.000000   0.0  0.0  \n",
       "2     0.000000  0.000000  0.0  0.000000  0.0  0.000000   0.0  0.0  \n",
       "3     0.000000  0.434463  0.0  0.000000  0.0  0.000000   0.0  0.0  \n",
       "4     0.420542  0.000000  0.0  0.000000  0.0  0.000000   0.0  0.0  \n",
       "...        ...       ...  ...       ...  ...       ...   ...  ...  \n",
       "3203  0.276736  0.000000  0.0  0.289726  0.0  0.000000   0.0  0.0  \n",
       "3204  0.000000  0.000000  0.0  0.000000  0.0  0.000000   0.0  0.0  \n",
       "3205  0.000000  0.000000  0.0  0.000000  0.0  0.000000   0.0  0.0  \n",
       "3206  0.000000  0.000000  0.0  0.000000  0.0  0.000000   0.0  0.0  \n",
       "3207  0.000000  0.000000  0.0  0.000000  0.0  0.000000   0.0  0.0  \n",
       "\n",
       "[3208 rows x 118 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = train_movie_scene_df['text']\n",
    "\n",
    "# Model TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100) #ograniczenie\n",
    "tfidf_tokens = tfidf_vectorizer.fit_transform(texts) #tylko kolumna z tekstem\n",
    "\n",
    "\n",
    "tfidf_texts = pd.DataFrame(tfidf_tokens.toarray(), columns= tfidf_vectorizer.get_feature_names_out().tolist()) #dataframe format\n",
    "tfidf_texts = tfidf_texts.reset_index()\n",
    "train_movie_scene_subtitles_df = pd.concat([train_movie_scene_df, tfidf_texts], axis=1) #polaczenie text+pozostale features\n",
    "\n",
    "display(train_movie_scene_subtitles_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11949366",
   "metadata": {},
   "source": [
    "#### 3. Learning with stratification\n",
    "Learn model on **train** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1380ca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.29      0.41        21\n",
      "           1       0.54      0.73      0.62       131\n",
      "           2       0.61      0.76      0.68       103\n",
      "           3       0.55      0.34      0.42        35\n",
      "           4       0.43      0.37      0.40        27\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.47      0.72      0.57        32\n",
      "           7       0.52      0.62      0.57        61\n",
      "           8       0.79      0.52      0.63        21\n",
      "           9       0.84      0.95      0.89       190\n",
      "          10       0.47      0.24      0.32       118\n",
      "          11       0.62      0.34      0.44        29\n",
      "          12       0.62      0.81      0.70        16\n",
      "          13       0.77      0.82      0.79       145\n",
      "          14       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.65       963\n",
      "   macro avg       0.60      0.51      0.51       963\n",
      "weighted avg       0.63      0.65      0.62       963\n",
      "\n",
      "Model accuracy: 0.6490134994807892\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\"index\", \"movie_id\", \"id\", \"label_movie\", \"start_sub\", \"end_sub\", \"text\", \"label_encoded\"]\n",
    "label_encoder = LabelEncoder()\n",
    "train_movie_scene_subtitles_df['label_encoded'] = label_encoder.fit_transform(train_movie_scene_subtitles_df['label_movie'])\n",
    "#train_movie_scene_subtitles_df.head()\n",
    "\n",
    "X = train_movie_scene_subtitles_df.drop(columns_to_drop, axis=1)\n",
    "X_norm = normalize_df(X)\n",
    "y = train_movie_scene_subtitles_df['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=23)\n",
    "\n",
    "criterion_options = ['entropy', 'log_loss']\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200, 50],\n",
    "    'max_depth': [None, 50, 80],\n",
    "    'min_samples_split': [10, 5, 15, 2],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'criterion': criterion_options,\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "# grid_search = GridSearchCV(RandomForestClassifier(random_state=randomstate),\n",
    "#                             param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "best_params={'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "model = RandomForestClassifier(random_state=randomstate, **best_params)\n",
    "model.fit(X_train, y_train)\n",
    "# log_loss: 90,1,11,300\n",
    "# entropy: 90, 1, 10, 250\n",
    "\n",
    "y_true, y_pred = y_test, model.predict(X_test)\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d20652a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params={'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(f\"best params={best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689c687",
   "metadata": {},
   "source": [
    "#### 4. Learn on full train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7e1cb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=None, n_estimators=200,\n",
       "                       random_state=40)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=None, n_estimators=200,\n",
       "                       random_state=40)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features=None, n_estimators=200,\n",
       "                       random_state=40)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_movie_scene_subtitles_df.drop(columns_to_drop, axis=1)\n",
    "X_train_norm = normalize_df(X_train)\n",
    "y_train = train_movie_scene_subtitles_df['label_encoded']\n",
    "\n",
    "model = RandomForestClassifier(random_state=randomstate, **best_params)\n",
    "model.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fac0d9",
   "metadata": {},
   "source": [
    "#### 5. Score prediction\n",
    "Scene prediction for **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b0c98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_movie_scene_df['text']\n",
    "test_tfidf_tokens = tfidf_vectorizer.transform(test_texts) #tylko kolumna z tekstem\n",
    "\n",
    "test_tfidf_texts = pd.DataFrame(test_tfidf_tokens.toarray(), columns= tfidf_vectorizer.get_feature_names_out().tolist()) #dataframe format\n",
    "test_tfidf_texts = test_tfidf_texts.reset_index(drop=True)\n",
    "\n",
    "test_movie_scene_subtitles_df = pd.concat([test_movie_scene_df, test_tfidf_texts], axis=1) #polaczenie text+pozostale features\n",
    "\n",
    "X_test = test_movie_scene_subtitles_df.drop([\"index\", \"movie_id\", \"id\", \"start_sub\", \"end_sub\", \"text\"], axis=1)\n",
    "X_test_norm = normalize_df(X_test)\n",
    "#display(X_test_norm)\n",
    "y_pred = model.predict(X_test_norm)\n",
    "\n",
    "predicted_labels = label_encoder.inverse_transform(y_pred)\n",
    "test_movie_scene_subtitles_df['Id'] = test_movie_scene_subtitles_df['movie_id'].astype(str) + '_' + test_movie_scene_subtitles_df['index'].astype(str)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Id': test_movie_scene_subtitles_df['Id'],\n",
    "    'Label': predicted_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72810be4-a2b5-42e9-bca4-89ed83fcf936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt1142988_0</td>\n",
       "      <td>Opening Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1285016_0</td>\n",
       "      <td>Opening Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1568346_0</td>\n",
       "      <td>Opening Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt1632708_0</td>\n",
       "      <td>Opening Image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0822832_1</td>\n",
       "      <td>Opening Image</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id          Label\n",
       "0  tt1142988_0  Opening Image\n",
       "1  tt1285016_0  Opening Image\n",
       "2  tt1568346_0  Opening Image\n",
       "3  tt1632708_0  Opening Image\n",
       "4  tt0822832_1  Opening Image"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f0079",
   "metadata": {},
   "source": [
    "### Save score\n",
    "\n",
    "Saving the final dataframe as an output file with a structure suitable for a Kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afd44277",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b305a516-dd45-4492-acce-405ed353c24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: Label\n",
      "All Is Lost                24\n",
      "B Story                   388\n",
      "Bad Guys Close In         360\n",
      "Break into Three           86\n",
      "Break into Two             58\n",
      "Catalyst                    6\n",
      "Dark Night of the Soul    191\n",
      "Debate                    228\n",
      "Final Image                67\n",
      "Finale                    448\n",
      "Fun and Games             168\n",
      "Midpoint                   36\n",
      "Opening Image              64\n",
      "Set-Up                    342\n",
      "Theme Stated                4\n",
      "Name: count, dtype: int64\n",
      "Labels used: 15 from 15\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Display useful score files statistics\n",
    "###\n",
    "\n",
    "label_counts = result_df['Label'].value_counts().sort_index()\n",
    "print(f\"predicted: {label_counts}\")\n",
    "print(f\"Labels used: {len(label_counts)} from 15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5d145-5530-4406-a8f8-2bd6233ea286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
